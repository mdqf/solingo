from flask import Blueprint, render_template, request, jsonify, session
from flask_login import login_required, current_user
from exercises import ExerciseGenerator
from datetime import datetime, timedelta
import random
import time
import math

from models import db, User, Word, UserWord, ReviewSession, ReviewLog

learning_bp = Blueprint('learning', __name__)

# ===== Spaced Repetition Engine (Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø± Ø§ÛŒÙ† ÙØ§ÛŒÙ„) =====
class SpacedRepetitionEngine:
    """Ù…ÙˆØªÙˆØ± ØªÚ©Ø±Ø§Ø± ÙØ§ØµÙ„Ù‡â€ŒØ¯Ø§Ø±"""
    
    BASE_INTERVALS = {
        'new': 1,      # 1 Ø³Ø§Ø¹Øª
        'learning': 6, # 6 Ø³Ø§Ø¹Øª
        'weak': 12,    # 12 Ø³Ø§Ø¹Øª
        'strong': 24,  # 1 Ø±ÙˆØ²
        'mastered': 48 # 2 Ø±ÙˆØ²
    }
    
    @staticmethod
    def calculate_review(user_word, is_correct, response_time):
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¨Ø¹Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø§Ø³Ø® Ú©Ø§Ø±Ø¨Ø±"""
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
        user_word.total_reviews += 1
        
        if is_correct:
            user_word.correct_reviews += 1
            user_word.consecutive_correct += 1
            
            # Ù¾Ø§Ø³Ø® Ø³Ø±ÛŒØ¹ = Ù‚Ø¯Ø±Øª Ø¨ÛŒØ´ØªØ±
            if response_time < 4:
                strength_increase = 0.25
            elif response_time < 8:
                strength_increase = 0.15
            else:
                strength_increase = 0.05
                
            # Ø¨ÙˆÙ†ÙˆØ³ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ
            if user_word.consecutive_correct > 3:
                strength_increase += min(0.2, user_word.consecutive_correct * 0.03)
                
            user_word.memory_strength = min(1.0, user_word.memory_strength + strength_increase)
        else:
            user_word.consecutive_correct = 0
            user_word.memory_strength = max(0.0, user_word.memory_strength - 0.4)
        
        # ØªØ¹ÛŒÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ø¬Ø¯ÛŒØ¯
        if user_word.memory_strength >= 0.9:
            new_state = 'mastered'
        elif user_word.memory_strength >= 0.7:
            new_state = 'strong'
        elif user_word.memory_strength >= 0.5:
            new_state = 'weak'
        elif user_word.memory_strength >= 0.3:
            new_state = 'learning'
        else:
            new_state = 'new'
            
        user_word.memory_state = new_state
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† Ù…Ø±ÙˆØ± Ø¨Ø¹Ø¯ÛŒ
        base_hours = SpacedRepetitionEngine.BASE_INTERVALS.get(new_state, 1)
        
        if is_correct:
            multiplier = 1.0 + (user_word.consecutive_correct * 0.5)
            strength_multiplier = 1.0 + (user_word.memory_strength * 2.0)
            total_multiplier = multiplier * strength_multiplier
        else:
            total_multiplier = 0.5
        
        # Ø§Ø¹Ù…Ø§Ù„ Ù†Ø±Ø® ÙØ±Ø³Ø§ÛŒØ´
        decay_factor = 1.5 - user_word.decay_rate
        total_multiplier *= decay_factor
        total_multiplier = max(0.5, min(total_multiplier, 10.0))
        
        interval_hours = base_hours * total_multiplier
        
        if interval_hours >= 24:
            interval_days = math.ceil(interval_hours / 24)
            next_review = datetime.utcnow() + timedelta(days=interval_days)
        else:
            next_review = datetime.utcnow() + timedelta(hours=interval_hours)
        
        user_word.next_review = next_review
        user_word.last_reviewed = datetime.utcnow()
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®
        if user_word.avg_response_time == 0:
            user_word.avg_response_time = response_time
        else:
            user_word.avg_response_time = (user_word.avg_response_time * (user_word.total_reviews - 1) + response_time) / user_word.total_reviews
        
        return {
            'next_review': next_review,
            'strength': user_word.memory_strength,
            'state': new_state,
            'consecutive_correct': user_word.consecutive_correct
        }
    
    @staticmethod
    def get_due_words(user_id, limit=20):
        """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ø§Øª Ù…ÙˆØ¹Ø¯ Ù…Ø±ÙˆØ±"""
        due_words = UserWord.query.filter(
            UserWord.user_id == user_id,
            UserWord.next_review <= datetime.utcnow(),
            UserWord.memory_state != 'mastered'
        ).order_by(
            UserWord.memory_strength.asc(),
            UserWord.next_review.asc()
        ).limit(limit).all()
        
        return due_words
    
    @staticmethod
    def get_new_words(user_id, limit=5):
        """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± - Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
        from sqlalchemy import and_, not_
        
        # Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†
        user = User.query.get(user_id)
        if not user:
            print(f"âŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
            return []
        
        user_level = user.current_level if user else 'A1'
        
        # **Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¬Ø¯ÛŒØ¯**: Ø§Ø² Ù¾Ø§ÛŒÙ‡â€ŒØ§ÛŒâ€ŒØªØ±ÛŒÙ† Ø¯Ø±Ø³ Ø´Ø±ÙˆØ¹ Ú©Ù†
        print(f"ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} (Ø³Ø·Ø­: {user_level})")
        
        # 1. Ø§Ø¨ØªØ¯Ø§ Ú©Ù„Ù…Ø§Øª A1 Ø¯Ø±Ø³ Û´ (Ù¾Ø§ÛŒÙ‡â€ŒØªØ±ÛŒÙ†)
        base_words = Word.query.filter(
            and_(
                Word.cefr_level == 'A1',
                Word.lesson == '4',
                not_(Word.id.in_(
                    db.session.query(UserWord.word_id)
                    .filter(UserWord.user_id == user_id)
                    .subquery()
                ))
            )
        ).order_by(
            Word.frequency_rank.asc()
        ).limit(limit).all()
        
        if base_words:
            print(f"âœ… {len(base_words)} Ú©Ù„Ù…Ù‡ Ø§Ø² Ø¯Ø±Ø³ Û´ Ø³Ø·Ø­ A1 Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
            return base_words
        
        print("âš ï¸ Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø±Ø³ Û´ Ø³Ø·Ø­ A1 Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
        
        # 2. Ø³Ù¾Ø³ Ø³Ø§ÛŒØ± Ú©Ù„Ù…Ø§Øª A1 Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø±Ø³
        a1_words = Word.query.filter(
            and_(
                Word.cefr_level == 'A1',
                not_(Word.id.in_(
                    db.session.query(UserWord.word_id)
                    .filter(UserWord.user_id == user_id)
                    .subquery()
                ))
            )
        ).order_by(
            Word.lesson.asc(),  # Ø§ÙˆÙ„ Ø¯Ø±Ø³â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±
            Word.frequency_rank.asc()
        ).limit(limit).all()
        
        if a1_words:
            print(f"âœ… {len(a1_words)} Ú©Ù„Ù…Ù‡ Ø§Ø² Ø³Ø§ÛŒØ± Ø¯Ø±Ø³â€ŒÙ‡Ø§ÛŒ A1 Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
            return a1_words
        
        print("âš ï¸ Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø³Ø·Ø­ A1 Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
        
        # 3. Ø§Ú¯Ø± Ø¯Ø± Ø³Ø·Ø­ Ú©Ø§Ø±Ø¨Ø± Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ø³Ø·ÙˆØ­ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†
        if user_level != 'A1':
            lower_level_words = Word.query.filter(
                and_(
                    Word.cefr_level == 'A1',
                    not_(Word.id.in_(
                        db.session.query(UserWord.word_id)
                        .filter(UserWord.user_id == user_id)
                        .subquery()
                    ))
                )
            ).order_by(
                Word.lesson.asc(),
                Word.frequency_rank.asc()
            ).limit(limit).all()
            
            if lower_level_words:
                print(f"âœ… {len(lower_level_words)} Ú©Ù„Ù…Ù‡ Ø§Ø² Ø³Ø·Ø­ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (A1) Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
                return lower_level_words
        
        print("âŒ Ù‡ÛŒÚ† Ú©Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
        return []
    
    @staticmethod
    def should_introduce_new_words(user_id, due_count):
        """ØªØ¹ÛŒÛŒÙ† Ø¢ÛŒØ§ Ø¨Ø§ÛŒØ¯ Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ù…Ø¹Ø±ÙÛŒ Ø´ÙˆØ¯ ÛŒØ§ Ù†Ù‡"""
        from models import UserWord
        
        # Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª Ú©Ø§Ø±Ø¨Ø±
        total_user_words = UserWord.query.filter_by(user_id=user_id).count()
        
        # ========== **Ø§ØµÙ„Ø§Ø­ Ø¨Ø­Ø±Ø§Ù†ÛŒ** ==========
        # Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯ â†’ Ø­ØªÙ…Ø§Ù‹ Ú©Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†
        if total_user_words == 0:
            print(f"ğŸ‘¤ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª. Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ù…Ø¹Ø±ÙÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            return True
        
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ú©Ù„Ù…Ø§Øª Ø²ÛŒØ§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø±ÙˆØ± Ø¯Ø§Ø±Ø¯ØŒ Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ù†Ú©Ù†
        if due_count >= 8:
            print(f"âš ï¸ Ú©Ø§Ø±Ø¨Ø± {user_id} Ú©Ù„Ù…Ø§Øª Ø²ÛŒØ§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø±ÙˆØ± Ø¯Ø§Ø±Ø¯ ({due_count}). Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            return False
        
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯ (Ø¨ÛŒØ´ Ø§Ø² Ûµ ØªØ§)ØŒ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†
        new_words_count = UserWord.query.filter_by(
            user_id=user_id,
            memory_state='new'
        ).count()
        
        if new_words_count > 5:
            print(f"âš ï¸ Ú©Ø§Ø±Ø¨Ø± {user_id} Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯ ({new_words_count}). Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            return False
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø³Ø¨Øª Ú©Ù„Ù…Ø§Øª ØªØ³Ù„Ø· ÛŒØ§ÙØªÙ‡
        mastered_count = UserWord.query.filter_by(
            user_id=user_id,
            memory_state='mastered'
        ).count()
        
        if total_user_words > 0:
            mastery_ratio = mastered_count / total_user_words
            
            # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ú©Ù…ØªØ± Ø§Ø² Û³Û°Ùª Ú©Ù„Ù…Ø§Øª Ø±Ø§ ØªØ³Ù„Ø· ÛŒØ§ÙØªÙ‡ØŒ Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
            if mastery_ratio < 0.3:
                print(f"âœ… Ú©Ø§Ø±Ø¨Ø± {user_id} ØªØ³Ù„Ø· Ú©Ù… ({mastery_ratio:.0%}). Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ù…Ø¹Ø±ÙÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
                return True
            else:
                print(f"âš ï¸ Ú©Ø§Ø±Ø¨Ø± {user_id} ØªØ³Ù„Ø· Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±Ø¯ ({mastery_ratio:.0%}). Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
                return False
        
        # Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†
        print(f"âœ… Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ù…Ø¹Ø±ÙÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return True

# ===== Routes =====
@learning_bp.route('/dashboard')
@login_required
def dashboard():
    """Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ú©Ø§Ø±Ø¨Ø±"""
    # Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±
    total_words = UserWord.query.filter_by(user_id=current_user.id).count()
    mastered_words = UserWord.query.filter_by(
        user_id=current_user.id,
        memory_state='mastered'
    ).count()
    
    # Ú©Ù„Ù…Ø§Øª Ø¨Ø±Ø§ÛŒ Ù…Ø±ÙˆØ± Ø§Ù…Ø±ÙˆØ²
    due_words_count = UserWord.query.filter(
        UserWord.user_id == current_user.id,
        UserWord.next_review <= datetime.utcnow(),
        UserWord.memory_state != 'mastered'
    ).count()
    
    # Ø¢Ø®Ø±ÛŒÙ† Ø³Ø´Ù†â€ŒÙ‡Ø§
    recent_sessions = ReviewSession.query.filter_by(
        user_id=current_user.id
    ).order_by(
        ReviewSession.started_at.desc()
    ).limit(5).all()
    
    # ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØª Ú©Ù„Ù…Ø§Øª
    status_distribution = {}
    states = ['new', 'learning', 'weak', 'strong', 'mastered']
    for state in states:
        count = UserWord.query.filter_by(
            user_id=current_user.id,
            memory_state=state
        ).count()
        status_distribution[state] = count
    
    return render_template('learning/dashboard.html',
                         user=current_user,
                         total_words=total_words,
                         mastered_words=mastered_words,
                         due_words=due_words_count,
                         recent_sessions=recent_sessions,
                         status_distribution=status_distribution)

@learning_bp.route('/review')
@login_required
def review():
    """ØµÙØ­Ù‡ Ù…Ø±ÙˆØ± Ùˆ ØªÙ…Ø±ÛŒÙ†"""
    return render_template('learning/review.html')

@learning_bp.route('/start_session', methods=['GET'])
@login_required
def start_session():
    """Ø´Ø±ÙˆØ¹ Ø¬Ù„Ø³Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¬Ø¯ÛŒØ¯ - ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ"""
    return render_template('learning/session_start.html')

@learning_bp.route('/api/start_session', methods=['GET'])
@login_required
def api_start_session():
    """API to start a learning session - returns JSON"""
    try:
        print(f"\n{'='*60}")
        print(log_user_state(current_user.id))
        print(f"{'='*60}\n")
        print(f"\nğŸš€ Starting session for user {current_user.id} ({current_user.username})")
        
        # Get words for review
        due_words = SpacedRepetitionEngine.get_due_words(current_user.id, limit=10)
        print(f"ğŸ“ Due words for review: {len(due_words)}")
        
        # Get new words
        new_words = []
        if SpacedRepetitionEngine.should_introduce_new_words(current_user.id, len(due_words)):
            new_words = SpacedRepetitionEngine.get_new_words(current_user.id, limit=5)
            print(f"ğŸ†• New words found: {len(new_words)}")
        else:
            print(f"â¸ï¸ No new words will be introduced")
        
        # ========== **Error Handling & State Validation** ==========
        # Detailed user status check
        
        # 1. Count total available words in user's level
        user_level = current_user.current_level or 'A1'
        total_words_in_level = Word.query.filter_by(cefr_level=user_level).count()
        
        # 2. Count current user's words
        total_user_words = UserWord.query.filter_by(user_id=current_user.id).count()
        
        print(f"ğŸ“Š User Statistics:")
        print(f"   - Level: {user_level}")
        print(f"   - Total available words: {total_words_in_level}")
        print(f"   - User's word count: {total_user_words}")
        print(f"   - Due words: {len(due_words)}")
        print(f"   - New words found: {len(new_words)}")
        
        # Various Scenarios
        if total_user_words == 0 and len(new_words) == 0:
            # New user but no words found in database
            print("âŒ New User: No words found in database")
            return jsonify({
                'success': False,
                'message': 'No words available for learning! Please load vocabulary first.',
                'has_words': False,
                'reason': 'no_words_in_database',
                'suggestion': '/load_vocabulary'
            })
        
        elif total_user_words == 0 and len(new_words) > 0:
            # New user and words available - normal state
            print(f"âœ… New User: {len(new_words)} new words being introduced")
            # Continue normal flow
        
        elif total_user_words > 0 and total_user_words >= total_words_in_level:
            # User has mastered all available words in this level
            print(f"ğŸ‰ User has mastered all {total_words_in_level} words in level {user_level}!")
            return jsonify({
                'success': False,
                'message': f'Well done! You have mastered all words in level {user_level}!',
                'has_words': False,
                'reason': 'all_words_mastered',
                'suggestion': 'level_up'
            })
        
        elif not due_words and not new_words:
            # Intermediate state - issue finding words
            print("âš ï¸ Unusual state: No words for review and no new words found")
            
            # Fallback: Try finding new words with less restriction
            fallback_new_words = SpacedRepetitionEngine.get_new_words(current_user.id, limit=10)
            if fallback_new_words:
                print(f"ğŸ”„ Fallback mode: {len(fallback_new_words)} new words found")
                new_words = fallback_new_words
            else:
                print("âŒ Fallback mode failed to find words")
                return jsonify({
                    'success': False,
                    'message': 'The system could not find any words to learn. Please try again.',
                    'has_words': False,
                    'reason': 'no_words_found',
                    'suggestion': 'retry'
                })

        # Final check for words before session creation
        if not due_words and not new_words:
            return jsonify({
                'success': False,
                'message': 'No words available for learning! Either you have finished all words or you need to load new ones.',
                'has_words': False
            })
        
        # Create Review Session
        review_session = ReviewSession(
            user_id=current_user.id,
            session_type='mixed',
            started_at=datetime.utcnow()
        )
        db.session.add(review_session)
        
        # Create UserWord records for new words and store IDs
        new_user_word_ids = []
        for word in new_words:
            # Check if UserWord already exists
            existing_user_word = UserWord.query.filter_by(
                user_id=current_user.id,
                word_id=word.id
            ).first()
            
            if not existing_user_word:
                user_word = UserWord(
                    user_id=current_user.id,
                    word_id=word.id,
                    memory_state='new',
                    next_review=datetime.utcnow()
                )
                db.session.add(user_word)
                db.session.flush()  # Flush to get the ID
                new_user_word_ids.append(user_word.id)
            else:
                new_user_word_ids.append(existing_user_word.id)
        
        # Commit changes
        db.session.commit()
        
        # Build session word list using the algorithm
        due_user_word_ids = [uw.id for uw in due_words]
        all_user_word_ids = build_session_words(due_user_word_ids, new_user_word_ids)
        
        if not all_user_word_ids:
            return jsonify({
                'success': False,
                'message': 'Error creating learning session',
                'has_words': False
            })
        
        # Store in Flask session
        session['current_session_id'] = review_session.id
        session['user_word_ids'] = all_user_word_ids  # Storing UserWord IDs only
        session['current_index'] = 0
        session['question_start_time'] = time.time()
        session['session_start_time'] = time.time()
        
        # Prepare the first word
        first_user_word_id = all_user_word_ids[0]
        first_user_word = UserWord.query.get(first_user_word_id)
        
        if not first_user_word:
            return jsonify({
                'success': False,
                'message': 'Error retrieving the first word',
                'has_words': False
            })
        
        word_data = _prepare_word_data(first_user_word)
        exercise = _generate_exercise_based_on_state(first_user_word)
        
        return jsonify({
            'success': True,
            'session_id': review_session.id,
            'exercise': exercise,
            'total_words': len(all_user_word_ids),
            'current_position': 1,
            'word_data': word_data,
            'has_words': True,
            'user_word_id': first_user_word_id
        })
        
    except Exception as e:
        db.session.rollback()
        return jsonify({
            'success': False,
            'message': f'Error starting session: {str(e)}',
            'has_words': False
        })

@learning_bp.route('/get_next_exercise')
@login_required
def get_next_exercise():
    """Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø±ÛŒÙ† Ø¨Ø¹Ø¯ÛŒ"""
    current_index = session.get('current_index', 0)
    user_word_ids = session.get('user_word_ids', [])
    
    if current_index >= len(user_word_ids):
        # Ù¾Ø§ÛŒØ§Ù† Ø¬Ù„Ø³Ù‡
        session_id = session.get('current_session_id')
        if session_id:
            review_session = ReviewSession.query.get(session_id)
            if review_session:
                review_session.completed_at = datetime.utcnow()
                review_session.total_questions = current_index
                db.session.commit()
        
        return jsonify({'finished': True})
    
    # Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ù‡ ÙØ¹Ù„ÛŒ
    user_word_id = user_word_ids[current_index]
    user_word = UserWord.query.get(user_word_id)
    
    if not user_word:
        # Ø§Ú¯Ø± UserWord Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø¨Ø±Ùˆ Ø¨Ù‡ Ø¨Ø¹Ø¯ÛŒ
        session['current_index'] = current_index + 1
        session['question_start_time'] = time.time()
        return get_next_exercise()
    
    # ØªÙ†Ø¸ÛŒÙ… Ø²Ù…Ø§Ù† Ø´Ø±ÙˆØ¹ Ø³ÙˆØ§Ù„
    session['question_start_time'] = time.time()
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙ…Ø±ÛŒÙ†
    word_data = _prepare_word_data(user_word)
    exercise = _generate_exercise_based_on_state(user_word)
    
    # Ø§ÙØ²Ø§ÛŒØ´ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„ Ø¨Ø¹Ø¯ÛŒ
    session['current_index'] = current_index + 1
    
    return jsonify({
        'exercise': exercise,
        'word_data': word_data,
        'user_word_id': user_word_id,
        'position': current_index + 1,
        'total': len(user_word_ids)
    })

@learning_bp.route('/submit_answer', methods=['POST'])
@login_required
def submit_answer():
    """Ø«Ø¨Øª Ù¾Ø§Ø³Ø® Ú©Ø§Ø±Ø¨Ø±"""
    data = request.json
    user_word_id = data.get('user_word_id')
    answer = data.get('answer')
    exercise_type = data.get('exercise_type')
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø® - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø²Ù…Ø§Ù† Ø´Ø±ÙˆØ¹ Ø³ÙˆØ§Ù„
    start_time = session.get('question_start_time', time.time())
    response_time = time.time() - start_time
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø®
    user_word = UserWord.query.get(user_word_id)
    if not user_word:
        return jsonify({
            'correct': False,
            'error': 'Ú©Ù„Ù…Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯'
        }), 404
    
    word = user_word.word
    is_correct = _check_answer(word, exercise_type, answer)
    
    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¨Ø§ Ù…ÙˆØªÙˆØ± ØªÚ©Ø±Ø§Ø± ÙØ§ØµÙ„Ù‡â€ŒØ¯Ø§Ø±
    result = SpacedRepetitionEngine.calculate_review(user_word, is_correct, response_time)
    
    # Ø«Ø¨Øª Ù„Ø§Ú¯
    review_log = ReviewLog(
        session_id=session.get('current_session_id'),
        user_word_id=user_word_id,
        exercise_type=exercise_type,
        response_time=response_time,
        was_correct=is_correct
    )
    db.session.add(review_log)
    
    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³Ø´Ù†
    review_session = ReviewSession.query.get(session.get('current_session_id'))
    if review_session:
        review_session.total_questions += 1
        if is_correct:
            review_session.total_correct += 1
        
        if user_word.memory_state == 'new':
            review_session.words_learned += 1
        else:
            review_session.words_reviewed += 1
    
    db.session.commit()
    
    # Ø¢Ù…Ø§Ø¯Ù‡ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® ØµØ­ÛŒØ­ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
    correct_answer = _get_correct_answer(word, exercise_type, answer)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø³ØªØ±ÛŒÚ©
    streak_info = calculate_streak_info(current_user.id, is_correct)
    
    return jsonify({
        'correct': is_correct,
        'feedback': {
            'next_review': result['next_review'].strftime('%Y-%m-%d %H:%M'),
            'strength': round(result['strength'] * 100),
            'state': result['state'],
            'consecutive_correct': result['consecutive_correct'],
            'response_time': round(response_time, 2)
        },
        'correct_answer': correct_answer,
        'streak': streak_info
    })


@learning_bp.route('/session_stats')
@login_required
def session_stats():
    """Ø¢Ù…Ø§Ø± Ø¬Ù„Ø³Ø§Øª Ú©Ø§Ø±Ø¨Ø±"""
    from datetime import datetime, timedelta
    
    # Ø¬Ù„Ø³Ø§Øª Û· Ø±ÙˆØ² Ø§Ø®ÛŒØ±
    week_ago = datetime.utcnow() - timedelta(days=7)
    recent_sessions = ReviewSession.query.filter(
        ReviewSession.user_id == current_user.id,
        ReviewSession.started_at >= week_ago
    ).all()
    
    stats = {
        'total_sessions': len(recent_sessions),
        'total_words_learned': sum(s.words_learned for s in recent_sessions),
        'total_words_reviewed': sum(s.words_reviewed for s in recent_sessions),
        'accuracy': calculate_accuracy(recent_sessions),
        'daily_activity': get_daily_activity(recent_sessions)
    }
    
    return jsonify(stats)

def calculate_accuracy(sessions):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚Øª Ú©Ø§Ø±Ø¨Ø±"""
    total_correct = sum(s.total_correct for s in sessions)
    total_questions = sum(s.total_questions for s in sessions)
    
    if total_questions > 0:
        return round((total_correct / total_questions) * 100, 1)
    return 0

def get_daily_activity(sessions):
    """ÙØ¹Ø§Ù„ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
    daily = {}
    for session in sessions:
        date = session.started_at.date().isoformat()
        if date not in daily:
            daily[date] = {
                'sessions': 0,
                'words': 0,
                'accuracy': 0
            }
        daily[date]['sessions'] += 1
        daily[date]['words'] += (session.words_learned + session.words_reviewed)
        if session.total_questions > 0:
            daily[date]['accuracy'] = round((session.total_correct / session.total_questions) * 100, 1)
    
    return daily

@learning_bp.route('/get_weak_words')
@login_required
def get_weak_words():
    """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ø§Øª Ø¶Ø¹ÛŒÙ Ú©Ø§Ø±Ø¨Ø±"""
    weak_words = UserWord.query.filter(
        UserWord.user_id == current_user.id,
        UserWord.memory_state.in_(['weak', 'learning']),
        UserWord.next_review <= datetime.utcnow()
    ).order_by(
        UserWord.memory_strength.asc()
    ).limit(20).all()
    
    words_data = []
    for uw in weak_words:
        word_data = _prepare_word_data(uw)
        word_data['strength'] = round(uw.memory_strength * 100)
        word_data['last_reviewed'] = uw.last_reviewed.strftime('%Y-%m-%d') if uw.last_reviewed else 'Ù‡Ø±Ú¯Ø²'
        words_data.append(word_data)
    
    return jsonify({'words': words_data})

@learning_bp.route('/practice_word/<int:user_word_id>')
@login_required
def practice_word(user_word_id):
    """ØªÙ…Ø±ÛŒÙ† Ø±ÙˆÛŒ Ú©Ù„Ù…Ù‡ Ø®Ø§Øµ"""
    user_word = UserWord.query.get_or_404(user_word_id)
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø§Ù„Ú©ÛŒØª
    if user_word.user_id != current_user.id:
        return jsonify({'error': 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²'}), 403
    
    # ØªÙˆÙ„ÛŒØ¯ ØªÙ…Ø±ÛŒÙ†
    word_data = _prepare_word_data(user_word)
    exercise = _generate_exercise(user_word)
    
    return jsonify({
        'exercise': exercise,
        'word_data': word_data,
        'message': 'ØªÙ…Ø±ÛŒÙ† Ø±ÙˆÛŒ Ú©Ù„Ù…Ù‡ Ø®Ø§Øµ'
    })

@learning_bp.route('/advanced_review')
@login_required
def advanced_review():
    """ØµÙØ­Ù‡ ØªÙ…Ø±ÛŒÙ† Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    return render_template('learning/advanced_review.html')

@learning_bp.route('/stats')
@login_required
def stats():
    """ØµÙØ­Ù‡ Ø¢Ù…Ø§Ø± Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§"""
    return render_template('learning/stats.html')

@learning_bp.route('/introduction/<int:word_id>')
@login_required
def word_introduction(word_id):
    """ØµÙØ­Ù‡ Ù…Ø¹Ø±ÙÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ú©Ù„Ù…Ù‡"""
    word = Word.query.get_or_404(word_id)
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ú©Ø§Ø±Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø§ÛŒÙ† Ú©Ù„Ù…Ù‡ Ø±Ø§ Ø¯ÛŒØ¯Ù‡
    user_word = UserWord.query.filter_by(
        user_id=current_user.id,
        word_id=word_id
    ).first()
    
    if not user_word:
        # Ø§ÛŒØ¬Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡
        user_word = UserWord(
            user_id=current_user.id,
            word_id=word_id,
            memory_state='new',
            next_review=datetime.utcnow()
        )
        db.session.add(user_word)
        db.session.commit()
    
    return render_template('learning/introduction.html', word=word, user_word=user_word)

@learning_bp.route('/start_learning_from_intro/<int:word_id>')
@login_required
def start_learning_from_intro(word_id):
    """Ø´Ø±ÙˆØ¹ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ú©Ù„Ù…Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ù…Ø¹Ø±ÙÛŒ"""
    # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø´Ù† Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ú©Ù„Ù…Ù‡
    review_session = ReviewSession(
        user_id=current_user.id,
        session_type='introduction',
        started_at=datetime.utcnow()
    )
    db.session.add(review_session)
    db.session.commit()
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø³Ø´Ù†
    session['current_session_id'] = review_session.id
    session['current_word_id'] = word_id
    session['is_introduction'] = True
    session['start_time'] = time.time()
    
    # Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ù‡
    user_word = UserWord.query.filter_by(
        user_id=current_user.id,
        word_id=word_id
    ).first_or_404()
    
    word_data = _prepare_word_data(user_word)
    exercise = _generate_exercise(user_word)
    
    return jsonify({
        'session_id': review_session.id,
        'exercise': exercise,
        'word_data': word_data,
        'is_introduction': True
    })

@learning_bp.route('/smart_start')
@login_required
def smart_start():
    """Ø´Ø±ÙˆØ¹ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¬Ø¯ÛŒØ¯"""
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ú©Ø§Ø±Ø¨Ø± Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡
    user_words_count = UserWord.query.filter_by(user_id=current_user.id).count()
    
    if user_words_count == 0:
        # Ú©Ø§Ø±Ø¨Ø± Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† Ú©Ù„Ù…Ù‡ Ø§Ø² Ø¯Ø±Ø³ Û´ Ø³Ø·Ø­ A1
        first_word = Word.query.filter_by(
            cefr_level='A1',
            lesson='4'
        ).order_by(
            Word.frequency_rank.asc()
        ).first()
        
        if first_word:
            # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù…Ø¹Ø±ÙÛŒ Ø§ÙˆÙ„ÛŒÙ† Ú©Ù„Ù…Ù‡
            return redirect(url_for('learning.word_introduction', word_id=first_word.id))
        else:
            # Ø§Ú¯Ø± Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ Ù†ÛŒØ³ØªØŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù„Ù…Ø§Øª
            flash('Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ú©Ù„Ù…Ø§Øª Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.', 'warning')
            return redirect(url_for('load_vocabulary'))
    else:
        # Ú©Ø§Ø±Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ú©Ù„Ù…Ø§ØªÛŒ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡
        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ Ù…Ø±ÙˆØ±
        due_words = SpacedRepetitionEngine.get_due_words(current_user.id, limit=1)
        
        if due_words:
            # Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø±ÙˆØ± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
            return redirect(url_for('learning.advanced_review'))
        else:
            # Ú©Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ú©Ù†
            new_words = SpacedRepetitionEngine.get_new_words(current_user.id, limit=1)
            if new_words:
                return redirect(url_for('learning.word_introduction', word_id=new_words[0].id))
            else:
                # Ù‡Ù…Ù‡ Ú©Ù„Ù…Ø§Øª Ø±Ø§ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡
                flash('Ø¢ÙØ±ÛŒÙ†! Ø´Ù…Ø§ ØªÙ…Ø§Ù… Ú©Ù„Ù…Ø§Øª Ø§ÛŒÙ† Ø³Ø·Ø­ Ø±Ø§ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡â€ŒØ§ÛŒØ¯.', 'success')
                return redirect(url_for('learning.dashboard'))

@learning_bp.route('/get_next_lesson')
@login_required
def get_next_lesson():
    """Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ø±Ø³ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ"""
    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡ Ø¯Ø± Ù‡Ø± Ø¯Ø±Ø³
    from sqlalchemy import func
    
    # Ø¢Ù…Ø§Ø± Ú©Ù„Ù…Ø§Øª ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡ Ø¯Ø± Ù‡Ø± Ø¯Ø±Ø³
    lesson_stats = db.session.query(
        Word.lesson,
        func.count(UserWord.id).label('learned'),
        func.count(Word.id).label('total')
    ).join(
        UserWord, UserWord.word_id == Word.id
    ).filter(
        UserWord.user_id == current_user.id,
        Word.lesson.isnot(None)
    ).group_by(
        Word.lesson
    ).all()
    
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¯Ø±Ø³â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù†Ø´Ø¯Ù‡
    incomplete_lessons = []
    for lesson, learned, total in lesson_stats:
        if learned < total:
            completion_rate = (learned / total) * 100
            incomplete_lessons.append({
                'lesson': lesson,
                'learned': learned,
                'total': total,
                'completion': completion_rate
            })
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø±ØµØ¯ ØªÚ©Ù…ÛŒÙ„ (Ú©Ù…ØªØ±ÛŒÙ† Ø§ÙˆÙ„)
    incomplete_lessons.sort(key=lambda x: x['completion'])
    
    if incomplete_lessons:
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ† Ø¯Ø±Ø³ Ù†Ø§Ù‚Øµ
        next_lesson = incomplete_lessons[0]['lesson']
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡ Ù†Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø¯Ø±Ø³
        learned_words_subquery = db.session.query(UserWord.word_id).filter(
            UserWord.user_id == current_user.id
        )
        
        next_words = Word.query.filter(
            Word.lesson == next_lesson,
            ~Word.id.in_(learned_words_subquery)
        ).order_by(
            Word.frequency_rank.asc()
        ).limit(3).all()
        
        return jsonify({
            'next_lesson': next_lesson,
            'completion': incomplete_lessons[0]['completion'],
            'next_words': [
                {
                    'id': w.id,
                    'lemma': w.lemma,
                    'translation': w.persian_translation
                }
                for w in next_words
            ]
        })
    
    # Ø§Ú¯Ø± Ù‡Ù…Ù‡ Ø¯Ø±Ø³â€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ØŒ Ø¯Ø±Ø³ Ø¨Ø¹Ø¯ÛŒ Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§ØªØ±
    return jsonify({
        'message': 'Ù‡Ù…Ù‡ Ø¯Ø±Ø³â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ† Ø³Ø·Ø­ Ø±Ø§ Ú©Ø§Ù…Ù„ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯!',
        'suggest_level_up': True
    })

@learning_bp.route('/api/start_practice_session', methods=['GET'])
@login_required
def api_start_practice_session():
    """Ø´Ø±ÙˆØ¹ Ø¬Ù„Ø³Ù‡ ØªÙ…Ø±ÛŒÙ† Ø±ÙˆÛŒ Ú©Ù„Ù…Ø§Øª Ø¶Ø¹ÛŒÙ"""
    # Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ø§Øª Ø¶Ø¹ÛŒÙ
    weak_words = UserWord.query.filter(
        UserWord.user_id == current_user.id,
        UserWord.memory_state.in_(['weak', 'learning']),
        UserWord.next_review <= datetime.utcnow()
    ).order_by(
        UserWord.memory_strength.asc()
    ).limit(10).all()
    
    if not weak_words:
        # Ø§Ú¯Ø± Ú©Ù„Ù…Ù‡ Ø¶Ø¹ÛŒÙÛŒ Ù†ÛŒØ³ØªØŒ Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ú©Ù†
        weak_words = SpacedRepetitionEngine.get_new_words(current_user.id, limit=10)
        if not weak_words:
            return jsonify({
                'success': False,
                'message': 'Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø±ÛŒÙ† Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.'
            })
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø´Ù†
    review_session = ReviewSession(
        user_id=current_user.id,
        session_type='practice',
        started_at=datetime.utcnow()
    )
    db.session.add(review_session)
    db.session.commit()
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø³Ø´Ù†
    session['current_session_id'] = review_session.id
    session['weak_word_ids'] = [uw.id for uw in weak_words]
    session['current_index'] = 0
    session['start_time'] = time.time()
    session['is_practice_session'] = True
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ† Ú©Ù„Ù…Ù‡
    first_word = weak_words[0]
    word_data = _prepare_word_data(first_word)
    exercise = _generate_exercise(first_word)
    
    return jsonify({
        'success': True,
        'session_id': review_session.id,
        'exercise': exercise,
        'total_words': len(weak_words),
        'current_position': 1,
        'word_data': word_data,
        'is_practice': True
    })

@learning_bp.route('/debug_user_state')
@login_required
def debug_user_state():
    """ØµÙØ­Ù‡ Ø¯ÛŒØ¨Ø§Ú¯ ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ø±Ø¨Ø±"""
    user_id = current_user.id
    
    # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
    user_info = {
        'id': user_id,
        'username': current_user.username,
        'level': current_user.current_level,
        'streak': current_user.streak_days,
        'last_active': current_user.last_active_date
    }
    
    # Ø¢Ù…Ø§Ø± Ú©Ù„Ù…Ø§Øª
    words_info = {
        'total_words_in_level': Word.query.filter_by(cefr_level=current_user.current_level or 'A1').count(),
        'user_words_total': UserWord.query.filter_by(user_id=user_id).count(),
        'due_words': len(SpacedRepetitionEngine.get_due_words(user_id)),
        'should_introduce_new': SpacedRepetitionEngine.should_introduce_new_words(user_id, 0),
        'new_words_available': len(SpacedRepetitionEngine.get_new_words(user_id, limit=10))
    }
    
    # ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØª
    states_dist = {}
    for state in ['new', 'learning', 'weak', 'strong', 'mastered']:
        states_dist[state] = UserWord.query.filter_by(
            user_id=user_id,
            memory_state=state
        ).count()
    
    return render_template('learning/debug_state.html',
                         user_info=user_info,
                         words_info=words_info,
                         states_dist=states_dist,
                         log=log_user_state(user_id))

# ===== ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ =====
def _prepare_word_data(user_word):
    """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ù…Ù‡"""
    word = user_word.word
    
    return {
        'user_word_id': user_word.id,
        'word_id': word.id,
        'lemma': word.lemma,
        'article': word.article,
        'plural': word.plural,
        'display_text': word.get_display_text(),  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ Ù…Ù‚Ø§Ù„Ù‡
        'translation': word.persian_translation,
        'example': word.example_german,
        'ipa': word.ipa,
        'type': user_word.memory_state,
        'part_of_speech': word.part_of_speech,
        'definition': word.german_definition,
        'lesson': word.lesson
    }

def _generate_exercise(user_word):
    """ØªÙˆÙ„ÛŒØ¯ ØªÙ…Ø±ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ¶Ø¹ÛŒØª Ú©Ù„Ù…Ù‡"""
    return ExerciseGenerator.generate_for_word(user_word.word, user_word)

def _get_multiple_choice_options(correct_word, count=4):
    """Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡ Ø¨Ø§ Ú¯Ø²ÛŒÙ†Ù‡ Ø§Ù†Ø­Ø±Ø§ÙÛŒ"""
    # Ú¯Ø²ÛŒÙ†Ù‡ ØµØ­ÛŒØ­
    options = [correct_word.persian_translation]
    
    # Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø­Ø±Ø§ÙÛŒ
    all_words = Word.query.filter(
        Word.id != correct_word.id,
        Word.cefr_level == correct_word.cefr_level
    ).limit(50).all()
    
    if len(all_words) >= count - 1:
        distractors = random.sample(all_words, count - 1)
        options.extend([word.persian_translation for word in distractors])
    else:
        # Ø§Ú¯Ø± Ú©Ù„Ù…Ø§Øª Ú©Ø§ÙÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        general_options = ['Ø³Ù„Ø§Ù…', 'Ø®Ø¯Ø§Ø­Ø§ÙØ¸', 'Ù…ØªØ´Ú©Ø±Ù…', 'Ù„Ø·ÙØ§Ù‹']
        options.extend(general_options[:count - 1])
    
    random.shuffle(options)
    return options

def _get_random_word_except(exclude_id):
    """ÛŒÚ© Ú©Ù„Ù…Ù‡ ØªØµØ§Ø¯ÙÛŒ ØºÛŒØ± Ø§Ø² Ú©Ù„Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡"""
    words = Word.query.filter(Word.id != exclude_id).limit(50).all()
    return random.choice(words) if words else None

def _check_answer(word, exercise_type, user_answer):
    """Ø¨Ø±Ø±Ø³ÛŒ ØµØ­Øª Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø§Ù†ÙˆØ§Ø¹ ØªÙ…Ø±ÛŒÙ†"""
    if exercise_type == 'multiple_choice':
        return user_answer == word.persian_translation
    
    elif exercise_type == 'typing':
        # ØªØ·Ø¨ÛŒÙ‚ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ± Ø¨Ø±Ø§ÛŒ ØªØ§ÛŒÙ¾ÛŒÙ†Ú¯
        correct = word.lemma.lower().strip()
        user = user_answer.lower().strip()
        
        # Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        correct = ' '.join(correct.split())
        user = ' '.join(user.split())
        
        # ØªØ·Ø¨ÛŒÙ‚ Ø¬Ø²Ø¦ÛŒ
        return correct == user
    
    elif exercise_type == 'article_choice':
        return user_answer == word.article
    
    elif exercise_type == 'sentence_completion':
        return user_answer.lower() == word.lemma.lower()
    
    elif exercise_type == 'listening':
        return user_answer.lower() == word.lemma.lower()
    
    elif exercise_type == 'recognition':
        return bool(user_answer)
    
    return False

def _get_correct_answer(word, exercise_type):
    """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® ØµØ­ÛŒØ­ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
    if exercise_type == 'multiple_choice':
        return word.persian_translation
    elif exercise_type == 'typing':
        return word.get_display_text()
    elif exercise_type == 'article_choice':
        return word.article
    elif exercise_type == 'sentence_completion':
        return word.lemma
    elif exercise_type == 'listening':
        return word.lemma
    else:
        return ''
    
def build_session_words(due_user_word_ids, new_user_word_ids):
    """Ø³Ø§Ø®Øª Ø¬Ù„Ø³Ù‡ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù…Ù†Ø§Ø³Ø¨"""
    # Ø§ÙˆÙ„ÙˆÛŒØª: Ú©Ù„Ù…Ø§Øª Ø¶Ø¹ÛŒÙ Ø§ÙˆÙ„ÙˆÛŒØª Ø§ÙˆÙ„
    weak_user_words = []
    learning_user_words = []
    other_due_user_words = []
    
    for uw_id in due_user_word_ids:
        user_word = UserWord.query.get(uw_id)
        if user_word:
            if user_word.memory_state == 'weak':
                weak_user_words.append(uw_id)
            elif user_word.memory_state == 'learning':
                learning_user_words.append(uw_id)
            else:
                other_due_user_words.append(uw_id)
    
    # ØªØ±Ú©ÛŒØ¨ Ø¬Ù„Ø³Ù‡ Ø¨Ø§ Ù†Ø³Ø¨Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨
    session_user_word_ids = []
    
    # 1. Ø­Ø¯Ø§Ú©Ø«Ø± Ûµ Ú©Ù„Ù…Ù‡ Ø¶Ø¹ÛŒÙ
    session_user_word_ids.extend(weak_user_words[:5])
    
    # 2. Ø­Ø¯Ø§Ú©Ø«Ø± Û³ Ú©Ù„Ù…Ù‡ Ø¯Ø± Ø­Ø§Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
    session_user_word_ids.extend(learning_user_words[:3])
    
    # 3. Ø­Ø¯Ø§Ú©Ø«Ø± Û² Ú©Ù„Ù…Ù‡ Ø¯ÛŒÚ¯Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø±ÙˆØ±
    session_user_word_ids.extend(other_due_user_words[:2])
    
    # 4. Ø­Ø¯Ø§Ú©Ø«Ø± Û´ Ú©Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯ (Ø§Ú¯Ø± ÙØ¶Ø§ÛŒ Ø®Ø§Ù„ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
    remaining_slots = 10 - len(session_user_word_ids)
    if remaining_slots > 0 and new_user_word_ids:
        session_user_word_ids.extend(new_user_word_ids[:remaining_slots])
    
    # Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ú©Ù…ØªØ± Ø§Ø² Ûµ Ú©Ù„Ù…Ù‡ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
    if len(session_user_word_ids) < 5 and new_user_word_ids:
        additional_needed = 5 - len(session_user_word_ids)
        already_added = len(session_user_word_ids) - (len(due_user_word_ids) + len(new_user_word_ids[:remaining_slots]))
        additional_new = new_user_word_ids[already_added:already_added + additional_needed]
        session_user_word_ids.extend(additional_new)
    
    # Ø¨Ù‡ Ù‡Ù… Ø±ÛŒØ®ØªÙ† ØªØ±ØªÛŒØ¨ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø³ØªÚ¯ÛŒ
    import random
    random.shuffle(session_user_word_ids)
    
    return session_user_word_ids

def _generate_exercise_based_on_state(user_word):
    """ØªÙˆÙ„ÛŒØ¯ ØªÙ…Ø±ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ¶Ø¹ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
    memory_state = user_word.memory_state
    consecutive_correct = user_word.consecutive_correct
    avg_response_time = user_word.avg_response_time
    
    # ØªØ¹ÛŒÛŒÙ† Ù†ÙˆØ¹ ØªÙ…Ø±ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ¶Ø¹ÛŒØª Ø­Ø§ÙØ¸Ù‡
    if memory_state in ['new']:
        # Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯: ØªÙ…Ø±ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ ØªØ´Ø®ÛŒØµÛŒ
        exercise_types = ['recognition', 'multiple_choice_article', 'multiple_choice']
        weights = [0.4, 0.4, 0.2]  # Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ ØªØ´Ø®ÛŒØµ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ù‚Ø§Ù„Ù‡
        
    elif memory_state in ['learning', 'weak']:
        # Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ø¯Ø± Ø­Ø§Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ø¶Ø¹ÛŒÙ: ØªÙ…Ø±ÛŒÙ†â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„
        if consecutive_correct >= 3:
            # Ø§Ú¯Ø± Ú†Ù†Ø¯ Ø¨Ø§Ø± Ù¾Ø´Øª Ù‡Ù… ØµØ­ÛŒØ­ Ø¬ÙˆØ§Ø¨ Ø¯Ø§Ø¯Ù‡ØŒ ØªÙ…Ø±ÛŒÙ† Ø³Ø®Øªâ€ŒØªØ±
            exercise_types = ['typing', 'sentence_completion', 'multiple_choice']
            weights = [0.5, 0.3, 0.2]
        else:
            # Ù‡Ù†ÙˆØ² Ø¯Ø± Ø­Ø§Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù¾Ø§ÛŒÙ‡
            exercise_types = ['multiple_choice', 'typing', 'article_choice']
            weights = [0.4, 0.4, 0.2]
            
    elif memory_state in ['strong', 'mastered']:
        # Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ù‚ÙˆÛŒ: ØªÙ…Ø±ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ú†Ø§Ù„Ø´ÛŒ
        if avg_response_time < 3:  # Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ¹
            exercise_types = ['typing', 'sentence_completion', 'reverse_translation']
            weights = [0.5, 0.3, 0.2]
        else:
            exercise_types = ['typing', 'multiple_choice', 'article_choice']
            weights = [0.4, 0.4, 0.2]
    
    else:
        # Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        exercise_types = ['multiple_choice', 'typing']
        weights = [0.5, 0.5]
    
    # Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ ØªÙ…Ø±ÛŒÙ† Ø¨Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† ÙˆØ²Ù†â€ŒÙ‡Ø§
    import random
    exercise_type = random.choices(exercise_types, weights=weights, k=1)[0]
    
    # ØªÙˆÙ„ÛŒØ¯ ØªÙ…Ø±ÛŒÙ†
    return _create_exercise_by_type(user_word, exercise_type)

def _create_exercise_by_type(user_word, exercise_type):
    """Ø§ÛŒØ¬Ø§Ø¯ ØªÙ…Ø±ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹"""
    word = user_word.word
    word_data = _prepare_word_data(user_word)
    
    if exercise_type == 'multiple_choice':
        options = _get_multiple_choice_options(word)
        return {
            'type': 'multiple_choice',
            'question': f"Ù…Ø¹Ù†ÛŒ '{word.get_display_text()}' Ú†ÛŒØ³ØªØŸ",
            'options': options,
            'correct_index': options.index(word.persian_translation),
            'difficulty': 'medium'
        }
    
    elif exercise_type == 'typing':
        return {
            'type': 'typing',
            'question': f"ØªØ±Ø¬Ù…Ù‡ Ø¢Ù„Ù…Ø§Ù†ÛŒ '{word.persian_translation}' Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:",
            'hint': word.part_of_speech,
            'difficulty': 'hard' if user_word.memory_state in ['strong', 'mastered'] else 'medium'
        }
    
    elif exercise_type == 'article_choice':
        articles = ['der', 'die', 'das']
        random.shuffle(articles)
        return {
            'type': 'article_choice',
            'question': f"Ù…Ù‚Ø§Ù„Ù‡ ØµØ­ÛŒØ­ Ø¨Ø±Ø§ÛŒ '{word.lemma}' Ú©Ø¯Ø§Ù… Ø§Ø³ØªØŸ",
            'options': articles,
            'correct_index': articles.index(word.article) if word.article in articles else 0,
            'hint': f"Ø¬Ù…Ø¹: {word.plural}" if word.plural else '',
            'difficulty': 'easy'
        }
    
    elif exercise_type == 'multiple_choice_article':
        # ØªÙ…Ø±ÛŒÙ† Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¹Ù†ÛŒ Ø¨Ø§ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù† Ù…Ù‚Ø§Ù„Ù‡
        options = _get_multiple_choice_options(word)
        return {
            'type': 'multiple_choice',
            'question': f"Ù…Ø¹Ù†ÛŒ '{word.article} {word.lemma}' Ú†ÛŒØ³ØªØŸ",
            'options': options,
            'correct_index': options.index(word.persian_translation),
            'difficulty': 'easy'
        }
    
    elif exercise_type == 'recognition':
        # Ø¢ÛŒØ§ Ø§ÛŒÙ† ØªØ±Ø¬Ù…Ù‡ ØµØ­ÛŒØ­ Ø§Ø³ØªØŸ
        is_correct = random.choice([True, False])
        if is_correct:
            return {
                'type': 'recognition',
                'question': f"Ø¢ÛŒØ§ '{word.get_display_text()}' Ø¨Ù‡ Ù…Ø¹Ù†ÛŒ '{word.persian_translation}' Ø§Ø³ØªØŸ",
                'is_correct': True,
                'difficulty': 'easy'
            }
        else:
            # Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù„Ù…Ù‡ ØªØµØ§Ø¯ÙÛŒ Ø¯ÛŒÚ¯Ø±
            wrong_word = _get_random_word_except(word.id)
            return {
                'type': 'recognition',
                'question': f"Ø¢ÛŒØ§ '{wrong_word.lemma if wrong_word else word.lemma}' Ø¨Ù‡ Ù…Ø¹Ù†ÛŒ '{word.persian_translation}' Ø§Ø³ØªØŸ",
                'is_correct': False,
                'difficulty': 'easy'
            }
    
    elif exercise_type == 'sentence_completion':
        if word.example_german:
            sentence = word.example_german
            blanked = sentence.replace(word.lemma, '__________')
            
            options = [word.lemma]
            distractors = _get_similar_words(word, 3)
            options.extend(distractors)
            random.shuffle(options)
            
            return {
                'type': 'sentence_completion',
                'question': 'Ø¬Ù…Ù„Ù‡ Ø±Ø§ Ú©Ø§Ù…Ù„ Ú©Ù†ÛŒØ¯:',
                'sentence': blanked,
                'options': options,
                'correct_index': options.index(word.lemma),
                'translation': word.example_persian if word.example_persian else '',
                'difficulty': 'hard'
            }
        else:
            # Ø§Ú¯Ø± Ù…Ø«Ø§Ù„ÛŒ Ù†Ø¯Ø§Ø±Ø¯ØŒ ØªÙ…Ø±ÛŒÙ† ØªØ§ÛŒÙ¾ÛŒÙ†Ú¯ Ø¨Ø¯Ù‡
            return _create_exercise_by_type(user_word, 'typing')
    
    elif exercise_type == 'reverse_translation':
        options = _get_multiple_choice_options(word, include_translation=False)
        options.append(word.lemma)
        random.shuffle(options)
        
        return {
            'type': 'reverse_translation',
            'question': f"Ú©Ø¯Ø§Ù… Ú¯Ø²ÛŒÙ†Ù‡ ØªØ±Ø¬Ù…Ù‡ Ø¢Ù„Ù…Ø§Ù†ÛŒ '{word.persian_translation}' Ø§Ø³ØªØŸ",
            'options': options,
            'correct_index': options.index(word.lemma),
            'difficulty': 'hard'
        }
    
    # Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    return _create_exercise_by_type(user_word, 'multiple_choice')

def calculate_streak_info(user_id, is_correct):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ±ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±"""
    from datetime import datetime, timedelta
    
    user = User.query.get(user_id)
    if not user:
        return {'current': 0, 'best': 0}
    
    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ø®Ø±ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØª
    user.last_active = datetime.utcnow()
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø³ØªØ±ÛŒÚ©
    today = datetime.utcnow().date()
    yesterday = today - timedelta(days=1)
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø®Ø±ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØª
    if user.last_active_date:
        last_active_date = user.last_active_date.date()
        
        if last_active_date == today:
            # Ø§Ù…Ø±ÙˆØ² Ù‚Ø¨Ù„Ø§Ù‹ ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§Ø´ØªÙ‡ØŒ Ø§Ø³ØªØ±ÛŒÚ© ØªØºÛŒÛŒØ± Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯
            pass
        elif last_active_date == yesterday:
            # Ø¯ÛŒØ±ÙˆØ² ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§Ø´ØªÙ‡ØŒ Ø§Ø³ØªØ±ÛŒÚ© Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯
            user.streak_days += 1
        else:
            # Ø¨ÛŒØ´ Ø§Ø² ÛŒÚ© Ø±ÙˆØ² ÙˆÙ‚ÙÙ‡ØŒ Ø§Ø³ØªØ±ÛŒÚ© Ø±ÛŒØ³Øª Ù…ÛŒâ€ŒØ´ÙˆØ¯
            user.streak_days = 1
    else:
        # Ø§ÙˆÙ„ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØª
        user.streak_days = 1
    
    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ø³ØªØ±ÛŒÚ©
    if user.streak_days > user.best_streak:
        user.best_streak = user.streak_days
    
    db.session.commit()
    
    return {
        'current': user.streak_days,
        'best': user.best_streak
    }

def _get_similar_words(word, count=3):
    """Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø±Ø§ÛŒ distractors"""
    # Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©Ù„Ù…Ø§Øª Ù‡Ù…â€ŒØ®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ø¯Ø± Ù‡Ù…Ø§Ù† Ø¯Ø±Ø³ Ùˆ Ø³Ø·Ø­
    similar_words = Word.query.filter(
        Word.id != word.id,
        Word.cefr_level == word.cefr_level,
        Word.part_of_speech == word.part_of_speech
    ).limit(20).all()
    
    if len(similar_words) >= count:
        import random
        selected = random.sample(similar_words, count)
        return [w.lemma for w in selected]
    
    # Ø§Ú¯Ø± Ú©Ø§ÙÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ú©Ù„Ù…Ø§Øª Ù‡Ù…â€ŒØ³Ø·Ø­
    same_level = Word.query.filter(
        Word.id != word.id,
        Word.cefr_level == word.cefr_level
    ).limit(50).all()
    
    if same_level:
        import random
        selected = random.sample(same_level, min(count, len(same_level)))
        return [w.lemma for w in selected]
    
    # Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    return ['Haus', 'Buch', 'Stadt'][:count]

def log_user_state(user_id):
    """Ù„Ø§Ú¯ ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯"""
    from models import UserWord, Word
    
    user = User.query.get(user_id)
    if not user:
        return "Ú©Ø§Ø±Ø¨Ø± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯"
    
    user_words = UserWord.query.filter_by(user_id=user_id).all()
    total_words = Word.query.filter_by(cefr_level=user.current_level or 'A1').count()
    
    log = f"""
ğŸ“‹ ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ø±Ø¨Ø± {user.username} (ID: {user_id}):
â”œâ”€ Ø³Ø·Ø­ ÙØ¹Ù„ÛŒ: {user.current_level}
â”œâ”€ Ú©Ù„ Ú©Ù„Ù…Ø§Øª Ù…ÙˆØ¬ÙˆØ¯: {total_words}
â”œâ”€ Ú©Ù„Ù…Ø§Øª Ú©Ø§Ø±Ø¨Ø±: {len(user_words)}
â”œâ”€ ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØª:
"""
    
    states = ['new', 'learning', 'weak', 'strong', 'mastered']
    for state in states:
        count = UserWord.query.filter_by(
            user_id=user_id,
            memory_state=state
        ).count()
        log += f"â”‚  â”œâ”€ {state}: {count}\n"
    
    log += f"â””â”€ Ú©Ù„Ù…Ø§Øª Ù…ÙˆØ¹Ø¯ Ù…Ø±ÙˆØ±: {len(SpacedRepetitionEngine.get_due_words(user_id))}"
    
    return log